{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé§ Gender Classification from Speech using Machine Learning\n",
    "\n",
    "This notebook demonstrates how to build a machine learning pipeline for **speech classification** ‚Äî specifically, classifying whether a speaker is male or female based on their voice recordings.\n",
    "\n",
    "We'll walk through the following steps:\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Objectives\n",
    "\n",
    "- Preprocess audio data to improve quality and consistency.\n",
    "- Extract relevant features from speech signals.\n",
    "- Train a machine learning model (Logistic Regression) for classification.\n",
    "- Evaluate model performance using accuracy and classification metrics.\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Techniques Used\n",
    "\n",
    "### üîâ Audio Preprocessing\n",
    "- **Trimming**: Remove silence from the beginning and end of the audio.\n",
    "- **Normalization**: Ensure audio levels are consistent across files.\n",
    "- **Resampling**: Convert all files to a consistent sampling rate.\n",
    "- **Padding/Truncating**: Ensure all inputs have the same length.\n",
    "\n",
    "### üìä Feature Extraction\n",
    "We extract powerful features that capture characteristics of the speaker‚Äôs voice:\n",
    "- **MFCCs (Mel-Frequency Cepstral Coefficients)**: Capture timbral and phonetic content.\n",
    "- **Spectral Centroid**: Measures the \"center of mass\" of frequencies.\n",
    "- **Spectral Rolloff**: Frequency below which a set percentage (e.g., 85%) of the energy is contained.\n",
    "- **Zero-Crossing Rate**: Counts how often the signal changes sign ‚Äî higher for noisy or unvoiced sounds.\n",
    "- **RMS Energy**: Captures the loudness of the signal.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Model\n",
    "We use a **Logistic Regression** model to classify audio based on extracted features. The model is trained on labeled examples of male and female voices.\n",
    "\n",
    "---\n",
    "\n",
    "## üìà Evaluation\n",
    "The final model is evaluated using:\n",
    "- **Accuracy**\n",
    "- **Precision, Recall, F1-Score**\n",
    "- **Confusion Matrix**\n",
    "\n",
    "---\n",
    "\n",
    "Let's get started!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:53.688142Z",
     "iopub.status.busy": "2025-05-20T18:37:53.687383Z",
     "iopub.status.idle": "2025-05-20T18:37:56.647672Z",
     "shell.execute_reply": "2025-05-20T18:37:56.646914Z",
     "shell.execute_reply.started": "2025-05-20T18:37:53.688117Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install noisereduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T19:02:11.78659Z",
     "iopub.status.busy": "2025-05-20T19:02:11.785864Z",
     "iopub.status.idle": "2025-05-20T19:02:14.69401Z",
     "shell.execute_reply": "2025-05-20T19:02:14.693234Z",
     "shell.execute_reply.started": "2025-05-20T19:02:11.786566Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install xgboost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-20T19:02:18.63591Z",
     "iopub.status.busy": "2025-05-20T19:02:18.635093Z",
     "iopub.status.idle": "2025-05-20T19:02:18.869978Z",
     "shell.execute_reply": "2025-05-20T19:02:18.869237Z",
     "shell.execute_reply.started": "2025-05-20T19:02:18.63587Z"
    }
   },
   "outputs": [],
   "source": [
    "# Standard Library\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Numerical and Data Processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Audio Processing\n",
    "import librosa\n",
    "import librosa.effects\n",
    "import noisereduce as nr\n",
    "import IPython.display as ipd\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Model Evaluation\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Model Utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting on a Sample\n",
    "\n",
    "let's take a sample and use it in experimenting and visualizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:56.656091Z",
     "iopub.status.busy": "2025-05-20T18:37:56.655859Z",
     "iopub.status.idle": "2025-05-20T18:37:56.669206Z",
     "shell.execute_reply": "2025-05-20T18:37:56.668673Z",
     "shell.execute_reply.started": "2025-05-20T18:37:56.656071Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = '/kaggle/input/gender-recognition-by-voiceoriginal/data/female/arctic_b0454.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Audio File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:56.67112Z",
     "iopub.status.busy": "2025-05-20T18:37:56.670702Z",
     "iopub.status.idle": "2025-05-20T18:37:56.690013Z",
     "shell.execute_reply": "2025-05-20T18:37:56.689513Z",
     "shell.execute_reply.started": "2025-05-20T18:37:56.671104Z"
    }
   },
   "outputs": [],
   "source": [
    "ipd.Audio(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:56.690898Z",
     "iopub.status.busy": "2025-05-20T18:37:56.690668Z",
     "iopub.status.idle": "2025-05-20T18:37:56.85072Z",
     "shell.execute_reply": "2025-05-20T18:37:56.850126Z",
     "shell.execute_reply.started": "2025-05-20T18:37:56.690878Z"
    }
   },
   "outputs": [],
   "source": [
    "x, sr = librosa.load(sample)\n",
    "\n",
    "pd.Series(x).plot(figsize=(8, 3), lw=1)\n",
    "plt.title('Audio Wave Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ‚úÇÔ∏è Trim Silence\n",
    "Removes unnecessary silence from the beginning and end of the audio. This helps eliminate parts of the audio that contain no useful information.\n",
    "\n",
    "We use `librosa.effects.trim()` function with a parameter `top_db` which stands for \"how many decibels below the peak\" should be considered silence.\n",
    "\n",
    "\"Decibels\" is a logarithmic unit used to measure sound level.\n",
    "\n",
    "* Lower `top_db` (e.g., `20`) ‚Üí stricter silence removal (only trims very quiet parts).\n",
    "* Higher `top_db` (e.g., `60`) ‚Üí more aggressive (trims even moderately quiet parts).\n",
    "\n",
    "We will choose `35` which is somewhat in the middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:56.85152Z",
     "iopub.status.busy": "2025-05-20T18:37:56.851316Z",
     "iopub.status.idle": "2025-05-20T18:37:56.986364Z",
     "shell.execute_reply": "2025-05-20T18:37:56.985807Z",
     "shell.execute_reply.started": "2025-05-20T18:37:56.851506Z"
    }
   },
   "outputs": [],
   "source": [
    "trimmed_x, index = librosa.effects.trim(x, top_db=35)\n",
    "pd.Series(trimmed_x).plot(figsize=(8, 2), lw=1)\n",
    "plt.title('Trimmed Audio Wave Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. üßº Noise Reduction\n",
    "\n",
    "Reduces background noise such as hums, hisses, or ambient sounds using filters or noise reduction algorithms.\n",
    "\n",
    "* High-pass filters remove low-frequency noise.\n",
    "* `noisereduce` library can automatically detect and reduce noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:56.987176Z",
     "iopub.status.busy": "2025-05-20T18:37:56.986984Z",
     "iopub.status.idle": "2025-05-20T18:37:57.170611Z",
     "shell.execute_reply": "2025-05-20T18:37:57.169953Z",
     "shell.execute_reply.started": "2025-05-20T18:37:56.987162Z"
    }
   },
   "outputs": [],
   "source": [
    "import noisereduce as nr\n",
    "\n",
    "denoised_x = nr.reduce_noise(y=trimmed_x, sr=sr)\n",
    "\n",
    "pd.Series(denoised_x).plot(figsize=(8, 2), lw=1)\n",
    "plt.title('Denoised Audio Wave Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. üìà Normalization\n",
    "\n",
    "Ensures all audio signals are on the same volume scale by scaling the waveform so its peak is consistent across samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:57.171587Z",
     "iopub.status.busy": "2025-05-20T18:37:57.171305Z",
     "iopub.status.idle": "2025-05-20T18:37:57.17559Z",
     "shell.execute_reply": "2025-05-20T18:37:57.175002Z",
     "shell.execute_reply.started": "2025-05-20T18:37:57.171563Z"
    }
   },
   "outputs": [],
   "source": [
    "normalized_x = librosa.util.normalize(denoised_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ‚è±Ô∏è Resampling (Optional)\n",
    "\n",
    "Resamples all audio to the same sampling rate (e.g. 16,000 Hz), which ensures uniformity across the dataset.\n",
    "\n",
    "Sample rate: how many samples per second are used to represent the audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:57.17637Z",
     "iopub.status.busy": "2025-05-20T18:37:57.176198Z",
     "iopub.status.idle": "2025-05-20T18:37:57.188991Z",
     "shell.execute_reply": "2025-05-20T18:37:57.188497Z",
     "shell.execute_reply.started": "2025-05-20T18:37:57.176356Z"
    }
   },
   "outputs": [],
   "source": [
    "resampled_x = librosa.resample(x, orig_sr=sr, target_sr=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. üß± Padding or Truncating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:57.19178Z",
     "iopub.status.busy": "2025-05-20T18:37:57.191293Z",
     "iopub.status.idle": "2025-05-20T18:37:57.332475Z",
     "shell.execute_reply": "2025-05-20T18:37:57.331891Z",
     "shell.execute_reply.started": "2025-05-20T18:37:57.191763Z"
    }
   },
   "outputs": [],
   "source": [
    "desired_length = 30000\n",
    "\n",
    "print(\"Length of our audio sample (x):\", len(x))\n",
    "resized_x = x\n",
    "\n",
    "if len(x) < desired_length:\n",
    "    resized_x = np.pad(x, (0, desired_length - len(x)))\n",
    "else:\n",
    "    resized_x = x[:desired_length]\n",
    "\n",
    "print('Length of our resized sample:', len(resized_x))\n",
    "pd.Series(resized_x).plot(figsize=(8, 2), lw=1)\n",
    "plt.title('Resized Audio Wave Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look the audio wave at a more zoomed level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:57.333264Z",
     "iopub.status.busy": "2025-05-20T18:37:57.333015Z",
     "iopub.status.idle": "2025-05-20T18:37:57.456704Z",
     "shell.execute_reply": "2025-05-20T18:37:57.456015Z",
     "shell.execute_reply.started": "2025-05-20T18:37:57.333245Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(denoised_x[9000:9500]).plot(figsize=(8, 2), lw=1)\n",
    "plt.title('Zoomed Audio Wave Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "Now let's look at various feature extraction techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. üìä Spectrogram\n",
    "\n",
    "Shows how the frequencies of the audio signal change over time.\n",
    "\n",
    "* **X-axis**: time\n",
    "* **Y-axis**: frequency\n",
    "* **Color**: amplitude (loudness) of each frequency at that moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:57.457647Z",
     "iopub.status.busy": "2025-05-20T18:37:57.457414Z",
     "iopub.status.idle": "2025-05-20T18:37:57.467081Z",
     "shell.execute_reply": "2025-05-20T18:37:57.466499Z",
     "shell.execute_reply.started": "2025-05-20T18:37:57.457625Z"
    }
   },
   "outputs": [],
   "source": [
    "transformed_x = librosa.stft(trimmed_x)\n",
    "db = librosa.amplitude_to_db(abs(transformed_x))\n",
    "db.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:57.46814Z",
     "iopub.status.busy": "2025-05-20T18:37:57.467932Z",
     "iopub.status.idle": "2025-05-20T18:37:57.982254Z",
     "shell.execute_reply": "2025-05-20T18:37:57.981651Z",
     "shell.execute_reply.started": "2025-05-20T18:37:57.468125Z"
    }
   },
   "outputs": [],
   "source": [
    "image = librosa.display.specshow(db, sr=sr, x_axis='time', y_axis='log')\n",
    "plt.colorbar(image)\n",
    "plt.title('Spectogram of Audio Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. üéµ Mel Spectogram\n",
    "\n",
    "Similar to a regular spectrogram, but the frequency axis is scaled to match how humans hear (the Mel scale).\n",
    "\n",
    "It focuses more on low to mid frequencies, which are most important for speech and music."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:57.983749Z",
     "iopub.status.busy": "2025-05-20T18:37:57.983181Z",
     "iopub.status.idle": "2025-05-20T18:37:58.000389Z",
     "shell.execute_reply": "2025-05-20T18:37:57.999727Z",
     "shell.execute_reply.started": "2025-05-20T18:37:57.983723Z"
    }
   },
   "outputs": [],
   "source": [
    "S = librosa.feature.melspectrogram(y=x, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:58.001436Z",
     "iopub.status.busy": "2025-05-20T18:37:58.001148Z",
     "iopub.status.idle": "2025-05-20T18:37:58.190624Z",
     "shell.execute_reply": "2025-05-20T18:37:58.189948Z",
     "shell.execute_reply.started": "2025-05-20T18:37:58.001421Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "S_db = librosa.power_to_db(S, ref=np.max)\n",
    "img = librosa.display.specshow(S_db, x_axis='time', y_axis='mel', sr=sr, fmax=8000, ax=ax)\n",
    "fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "ax.set(title='Mel-frequency spectogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. üéØ Spectral Centroid\n",
    "\n",
    "The Spectral Centroid tells us where the \"center of mass\" of the sound frequencies is ‚Äî it shows us how \"bright\" or \"dark\" a sound is.\n",
    "\n",
    "* If most energy is in high frequencies, the centroid is high ‚Üí the sound is bright or sharp (like cymbals).\n",
    "* If most energy is in low frequencies, the centroid is low ‚Üí the sound is dull or bassy (like drums or male voices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:58.191634Z",
     "iopub.status.busy": "2025-05-20T18:37:58.191376Z",
     "iopub.status.idle": "2025-05-20T18:37:58.214304Z",
     "shell.execute_reply": "2025-05-20T18:37:58.213859Z",
     "shell.execute_reply.started": "2025-05-20T18:37:58.191613Z"
    }
   },
   "outputs": [],
   "source": [
    "cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
    "frames = range(len(cent))\n",
    "time = librosa.frames_to_time(frames)\n",
    "S, phase = librosa.magphase(librosa.stft(y=x))\n",
    "freqs, times, D = librosa.reassigned_spectrogram(x, fill_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:58.215333Z",
     "iopub.status.busy": "2025-05-20T18:37:58.2151Z",
     "iopub.status.idle": "2025-05-20T18:37:58.49049Z",
     "shell.execute_reply": "2025-05-20T18:37:58.489825Z",
     "shell.execute_reply.started": "2025-05-20T18:37:58.215313Z"
    }
   },
   "outputs": [],
   "source": [
    "times = librosa.times_like(cent)\n",
    "fig, ax = plt.subplots()\n",
    "librosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max),\n",
    "                         y_axis='log', x_axis='time', ax=ax)\n",
    "ax.plot(times, cent.T, label='Spectral centroid', color='w')\n",
    "fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "ax.legend(loc='upper right')\n",
    "ax.set(title='log Power Spectrogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ‚ö° Zero Crossings (ZCR)\n",
    "\n",
    "Counts how often the waveform changes sign (+ to - or - to +).\n",
    "\n",
    "* High ZCR ‚Üí Noisy, sharp, or high-pitched sounds\n",
    "* Low ZCR ‚Üí Smooth, low, bassy sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:58.491408Z",
     "iopub.status.busy": "2025-05-20T18:37:58.491202Z",
     "iopub.status.idle": "2025-05-20T18:37:58.628803Z",
     "shell.execute_reply": "2025-05-20T18:37:58.628156Z",
     "shell.execute_reply.started": "2025-05-20T18:37:58.491385Z"
    }
   },
   "outputs": [],
   "source": [
    "n0 = 10000\n",
    "n1 = 10050\n",
    "pd.Series(x[n0:n1]).plot(figsize = (8, 3), lw = 1)\n",
    "plt.title(\"Zoomed Audio Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:58.629844Z",
     "iopub.status.busy": "2025-05-20T18:37:58.629533Z",
     "iopub.status.idle": "2025-05-20T18:37:58.634516Z",
     "shell.execute_reply": "2025-05-20T18:37:58.633827Z",
     "shell.execute_reply.started": "2025-05-20T18:37:58.629827Z"
    }
   },
   "outputs": [],
   "source": [
    "zero_crossings = librosa.zero_crossings(x[n0:n1], pad=False)\n",
    "print(zero_crossings.shape)\n",
    "print(\"Number of Zero Crossings: \", sum(zero_crossings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. üåä Spectral Rolloff\n",
    "\n",
    "Tells us the frequency, where below this frequency (point) is 85% of the total energy (amplitude) in the sound.\n",
    "\n",
    "#### Example:\n",
    "üßî Male Voice (Deep, Low-pitched)\n",
    "\n",
    "* Most energy is in low frequencies.\n",
    "* We might reach 85% of the energy by 2000 Hz.\n",
    "* ‚úÖ So the Spectral Rolloff is low.\n",
    "\n",
    "üë© Female Voice (High-pitched)\n",
    "\n",
    "* Energy is spread into higher frequencies.\n",
    "* We may need to go up to 5000 Hz to reach 85% of the energy.\n",
    "* ‚úÖ So the Spectral Rolloff is higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:58.635474Z",
     "iopub.status.busy": "2025-05-20T18:37:58.635249Z",
     "iopub.status.idle": "2025-05-20T18:37:58.650922Z",
     "shell.execute_reply": "2025-05-20T18:37:58.650313Z",
     "shell.execute_reply.started": "2025-05-20T18:37:58.635415Z"
    }
   },
   "outputs": [],
   "source": [
    "rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)[0]\n",
    "print('Rolloff Shape:', rolloff.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. üéº MFCC (Mel-Frequency Cepstral Coefficients)\n",
    "Captures the overall shape of the audio spectrum in a way that mimics human hearing. Commonly used in speech and music analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:58.652064Z",
     "iopub.status.busy": "2025-05-20T18:37:58.651795Z",
     "iopub.status.idle": "2025-05-20T18:37:58.735643Z",
     "shell.execute_reply": "2025-05-20T18:37:58.735086Z",
     "shell.execute_reply.started": "2025-05-20T18:37:58.652039Z"
    }
   },
   "outputs": [],
   "source": [
    "mfccs = librosa.feature.mfcc(y=x, sr=sr)\n",
    "print(\"MFCCs Shape:\", mfccs.shape)\n",
    "\n",
    "librosa.display.specshow(mfccs, sr=sr, x_axis='time')\n",
    "plt.title('MFCCs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. üìâ RMS (Root Mean Square Energy)\n",
    "\n",
    "Captures the energy or loudness of the signal over time. Useful for understanding how powerful the sound is at each frame.\n",
    "\n",
    "* High RMS values = loud parts (e.g., speech, music, noise).\n",
    "* Low RMS values = silence or quiet parts.\n",
    "\n",
    "It helps in voice activity detection, emotion recognition, and even trimming silent segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:58.736663Z",
     "iopub.status.busy": "2025-05-20T18:37:58.736245Z",
     "iopub.status.idle": "2025-05-20T18:37:58.740787Z",
     "shell.execute_reply": "2025-05-20T18:37:58.740154Z",
     "shell.execute_reply.started": "2025-05-20T18:37:58.736647Z"
    }
   },
   "outputs": [],
   "source": [
    "rms = librosa.feature.rms(y=x)[0]\n",
    "\n",
    "# Get time axis for plotting\n",
    "frames = range(len(rms))\n",
    "t = librosa.frames_to_time(frames, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:58.741884Z",
     "iopub.status.busy": "2025-05-20T18:37:58.741606Z",
     "iopub.status.idle": "2025-05-20T18:37:58.921064Z",
     "shell.execute_reply": "2025-05-20T18:37:58.9204Z",
     "shell.execute_reply.started": "2025-05-20T18:37:58.741868Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(t, rms, label='RMS Energy', color='orange')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Energy')\n",
    "plt.title('RMS Energy Over Time')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Preprocessing on Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:58.922011Z",
     "iopub.status.busy": "2025-05-20T18:37:58.921836Z",
     "iopub.status.idle": "2025-05-20T18:37:58.925397Z",
     "shell.execute_reply": "2025-05-20T18:37:58.924584Z",
     "shell.execute_reply.started": "2025-05-20T18:37:58.921997Z"
    }
   },
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 16000 # Standard rate for speech models\n",
    "DURATION = 3 # seconds\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:58.926389Z",
     "iopub.status.busy": "2025-05-20T18:37:58.926146Z",
     "iopub.status.idle": "2025-05-20T18:37:58.937171Z",
     "shell.execute_reply": "2025-05-20T18:37:58.936499Z",
     "shell.execute_reply.started": "2025-05-20T18:37:58.926373Z"
    }
   },
   "outputs": [],
   "source": [
    "def PreprocessAudio(file_path):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "        \n",
    "        # trim silence\n",
    "        y, _ = librosa.effects.trim(y)\n",
    "        \n",
    "        # reduce noise\n",
    "        y = nr.reduce_noise(y=y, sr=sr)\n",
    "        \n",
    "        # normalize\n",
    "        y = librosa.util.normalize(y)\n",
    "\n",
    "        # padding/truncating\n",
    "        if len(y) < SAMPLES_PER_TRACK:\n",
    "            y = np.pad(y, (0, SAMPLES_PER_TRACK - len(y)))\n",
    "        else:\n",
    "            y = y[:SAMPLES_PER_TRACK]\n",
    "\n",
    "        return y, sr\n",
    "    except Exception as error:\n",
    "        print(f\"Failed to process '{file_path}': {error}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:58.938397Z",
     "iopub.status.busy": "2025-05-20T18:37:58.937918Z",
     "iopub.status.idle": "2025-05-20T18:37:58.947868Z",
     "shell.execute_reply": "2025-05-20T18:37:58.94732Z",
     "shell.execute_reply.started": "2025-05-20T18:37:58.938375Z"
    }
   },
   "outputs": [],
   "source": [
    "def ExtractAudioFeatures(file_path):\n",
    "    audio_signal, sample_rate = PreprocessAudio(file_path)\n",
    "    if audio_signal is None:\n",
    "        return None\n",
    "\n",
    "    n_fft = 2048  # means 2048 samples per window (~128ms if sr=16k)\n",
    "    hop_length = 512  # means we move 512 samples forward for next window (~32ms)\n",
    "    \n",
    "    mfcc = librosa.feature.mfcc(y=audio_signal, sr=sample_rate, n_mfcc=13, hop_length=hop_length, n_fft=n_fft)\n",
    "    mfcc_mean = np.mean(mfcc, axis=1)\n",
    "\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=audio_signal, sr=sample_rate, hop_length=hop_length, n_fft=n_fft)[0]\n",
    "    rolloff_mean = np.mean(rolloff)\n",
    "\n",
    "    zcr = librosa.feature.zero_crossing_rate(y=audio_signal, hop_length=hop_length)[0]\n",
    "    zcr_mean = np.mean(zcr)\n",
    "\n",
    "    centroid = librosa.feature.spectral_centroid(y=audio_signal, sr=sample_rate, hop_length=hop_length, n_fft=n_fft)[0]\n",
    "    centroid_mean = np.mean(centroid)\n",
    "\n",
    "    rms = librosa.feature.rms(y=audio_signal, hop_length=hop_length)[0]\n",
    "    rms_mean = np.mean(rms)\n",
    "\n",
    "    combined_features = np.hstack([\n",
    "        mfcc_mean,\n",
    "        rolloff_mean,\n",
    "        zcr_mean,\n",
    "        centroid_mean,\n",
    "        rms_mean\n",
    "    ])\n",
    "\n",
    "    return combined_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:58.948867Z",
     "iopub.status.busy": "2025-05-20T18:37:58.948629Z",
     "iopub.status.idle": "2025-05-20T18:37:58.961099Z",
     "shell.execute_reply": "2025-05-20T18:37:58.960517Z",
     "shell.execute_reply.started": "2025-05-20T18:37:58.948844Z"
    }
   },
   "outputs": [],
   "source": [
    "male_folder = '/kaggle/input/gender-recognition-by-voiceoriginal/data/male/'\n",
    "female_folder = '/kaggle/input/gender-recognition-by-voiceoriginal/data/female'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:58.965194Z",
     "iopub.status.busy": "2025-05-20T18:37:58.96475Z",
     "iopub.status.idle": "2025-05-20T18:37:58.974268Z",
     "shell.execute_reply": "2025-05-20T18:37:58.973704Z",
     "shell.execute_reply.started": "2025-05-20T18:37:58.965177Z"
    }
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:58.975064Z",
     "iopub.status.busy": "2025-05-20T18:37:58.974835Z",
     "iopub.status.idle": "2025-05-20T18:37:58.984563Z",
     "shell.execute_reply": "2025-05-20T18:37:58.983883Z",
     "shell.execute_reply.started": "2025-05-20T18:37:58.975041Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_male_file(file_path):\n",
    "    features = ExtractAudioFeatures(file_path)\n",
    "    if features is not None:\n",
    "        return (features, 'male')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the two folders are large (`male_folder` contains 10.5k files), we will use parallel processing to speed up the process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:37:58.98533Z",
     "iopub.status.busy": "2025-05-20T18:37:58.985168Z",
     "iopub.status.idle": "2025-05-20T18:50:08.240908Z",
     "shell.execute_reply": "2025-05-20T18:50:08.240249Z",
     "shell.execute_reply.started": "2025-05-20T18:37:58.985318Z"
    }
   },
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "# get all file paths first\n",
    "file_paths = [os.path.join(male_folder, f) for f in os.listdir(male_folder) if os.path.isfile(os.path.join(male_folder, f))]\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    results = list(tqdm(executor.map(process_male_file, file_paths), total=len(file_paths)))\n",
    "\n",
    "for result in results:\n",
    "    if result is not None:\n",
    "        features, label = result\n",
    "        data.append(features)\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:50:08.241904Z",
     "iopub.status.busy": "2025-05-20T18:50:08.241671Z",
     "iopub.status.idle": "2025-05-20T18:50:08.245318Z",
     "shell.execute_reply": "2025-05-20T18:50:08.244771Z",
     "shell.execute_reply.started": "2025-05-20T18:50:08.241887Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_female_file(file_path):\n",
    "    features = ExtractAudioFeatures(file_path)\n",
    "    if features is not None:\n",
    "        return (features, 'female')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:50:08.246409Z",
     "iopub.status.busy": "2025-05-20T18:50:08.246172Z",
     "iopub.status.idle": "2025-05-20T18:56:47.299281Z",
     "shell.execute_reply": "2025-05-20T18:56:47.298499Z",
     "shell.execute_reply.started": "2025-05-20T18:50:08.246394Z"
    }
   },
   "outputs": [],
   "source": [
    "file_paths = [os.path.join(female_folder, f) for f in os.listdir(female_folder) if os.path.isfile(os.path.join(female_folder, f))]\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    results = list(tqdm(executor.map(process_female_file, file_paths), total=len(file_paths)))\n",
    "\n",
    "for result in results:\n",
    "    if result is not None:\n",
    "        features, label = result\n",
    "        data.append(features)\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we loaded our two folders, we can create our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:57:55.010164Z",
     "iopub.status.busy": "2025-05-20T18:57:55.009665Z",
     "iopub.status.idle": "2025-05-20T18:57:55.084972Z",
     "shell.execute_reply": "2025-05-20T18:57:55.084465Z",
     "shell.execute_reply.started": "2025-05-20T18:57:55.010143Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df['gender'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:57:57.094794Z",
     "iopub.status.busy": "2025-05-20T18:57:57.094546Z",
     "iopub.status.idle": "2025-05-20T18:57:57.125117Z",
     "shell.execute_reply": "2025-05-20T18:57:57.124577Z",
     "shell.execute_reply.started": "2025-05-20T18:57:57.094776Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_columns = ([f\"mfcc_{i+1}\" for i in range(13)] +[\"spectral_rolloff\", \"zero_crossing_rate\", \"spectral_centroid\", \"rms\"])\n",
    "\n",
    "df.columns = feature_columns + ['gender']\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA & Preprocessing\n",
    "\n",
    "Now let's explore our constructed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:57:57.563744Z",
     "iopub.status.busy": "2025-05-20T18:57:57.563551Z",
     "iopub.status.idle": "2025-05-20T18:57:57.582744Z",
     "shell.execute_reply": "2025-05-20T18:57:57.582173Z",
     "shell.execute_reply.started": "2025-05-20T18:57:57.563731Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:57:57.594772Z",
     "iopub.status.busy": "2025-05-20T18:57:57.594563Z",
     "iopub.status.idle": "2025-05-20T18:57:57.598698Z",
     "shell.execute_reply": "2025-05-20T18:57:57.597929Z",
     "shell.execute_reply.started": "2025-05-20T18:57:57.594757Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Data Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:57:57.609653Z",
     "iopub.status.busy": "2025-05-20T18:57:57.609413Z",
     "iopub.status.idle": "2025-05-20T18:57:57.650256Z",
     "shell.execute_reply": "2025-05-20T18:57:57.649761Z",
     "shell.execute_reply.started": "2025-05-20T18:57:57.609638Z"
    }
   },
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:57:57.675058Z",
     "iopub.status.busy": "2025-05-20T18:57:57.67464Z",
     "iopub.status.idle": "2025-05-20T18:57:57.681254Z",
     "shell.execute_reply": "2025-05-20T18:57:57.68057Z",
     "shell.execute_reply.started": "2025-05-20T18:57:57.675044Z"
    }
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:57:57.768075Z",
     "iopub.status.busy": "2025-05-20T18:57:57.767665Z",
     "iopub.status.idle": "2025-05-20T18:57:57.798074Z",
     "shell.execute_reply": "2025-05-20T18:57:57.797565Z",
     "shell.execute_reply.started": "2025-05-20T18:57:57.76806Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Number of Duplicates:\", df.duplicated().sum())\n",
    "print(f\"Percentage of Duplicates: {df.duplicated().sum() / len(df) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:57:57.823896Z",
     "iopub.status.busy": "2025-05-20T18:57:57.823445Z",
     "iopub.status.idle": "2025-05-20T18:57:57.852022Z",
     "shell.execute_reply": "2025-05-20T18:57:57.851341Z",
     "shell.execute_reply.started": "2025-05-20T18:57:57.823881Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "print(\"Dropped Duplicates\")\n",
    "print(f\"Percentage of Duplicates: {df.duplicated().sum() / len(df) * 100:.2f}%\")\n",
    "print(\"Data Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:57:57.933044Z",
     "iopub.status.busy": "2025-05-20T18:57:57.932678Z",
     "iopub.status.idle": "2025-05-20T18:57:58.010546Z",
     "shell.execute_reply": "2025-05-20T18:57:58.009966Z",
     "shell.execute_reply.started": "2025-05-20T18:57:57.93303Z"
    }
   },
   "outputs": [],
   "source": [
    "gender_counts = df['gender'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.pie(gender_counts, labels=gender_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Gender Distribution')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that we have a class imbalance in our target variable\n",
    "\n",
    "To resolve this issue, we will assign weights to each of them in training phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:57:58.061518Z",
     "iopub.status.busy": "2025-05-20T18:57:58.061305Z",
     "iopub.status.idle": "2025-05-20T18:58:00.47466Z",
     "shell.execute_reply": "2025-05-20T18:58:00.473877Z",
     "shell.execute_reply.started": "2025-05-20T18:57:58.061502Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_columns = df.columns[:-1]\n",
    "df[feature_columns].hist(bins=30, figsize=(20, 15))\n",
    "plt.suptitle('Feature Distributions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:58:00.475978Z",
     "iopub.status.busy": "2025-05-20T18:58:00.475765Z",
     "iopub.status.idle": "2025-05-20T18:58:02.481069Z",
     "shell.execute_reply": "2025-05-20T18:58:02.480258Z",
     "shell.execute_reply.started": "2025-05-20T18:58:00.475962Z"
    }
   },
   "outputs": [],
   "source": [
    "n = len(feature_columns)\n",
    "\n",
    "rows = (n + 1) // 2\n",
    "cols = 2\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(12, 3 * rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(feature_columns):\n",
    "    sns.boxplot(x='gender', y=col, data=df, ax=axes[i])\n",
    "    axes[i].set_title(f'{col}')\n",
    "\n",
    "# Hide any unused plots\n",
    "for j in range(i+1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:59:36.357608Z",
     "iopub.status.busy": "2025-05-20T18:59:36.357304Z",
     "iopub.status.idle": "2025-05-20T18:59:36.379912Z",
     "shell.execute_reply": "2025-05-20T18:59:36.379403Z",
     "shell.execute_reply.started": "2025-05-20T18:59:36.357584Z"
    }
   },
   "outputs": [],
   "source": [
    "numerical_columns = df.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "Q1 = df[numerical_columns].quantile(0.25)\n",
    "Q3 = df[numerical_columns].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df = df[~((df[numerical_columns] < (Q1 - 1.5 * IQR)) | \n",
    "              (df[numerical_columns] > (Q3 + 1.5 * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:59:39.189001Z",
     "iopub.status.busy": "2025-05-20T18:59:39.188793Z",
     "iopub.status.idle": "2025-05-20T18:59:39.193931Z",
     "shell.execute_reply": "2025-05-20T18:59:39.19321Z",
     "shell.execute_reply.started": "2025-05-20T18:59:39.188987Z"
    }
   },
   "outputs": [],
   "source": [
    "df['gender'] = df['gender'].map({\n",
    "    'male': 1,\n",
    "    'female': 0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:59:41.109317Z",
     "iopub.status.busy": "2025-05-20T18:59:41.109043Z",
     "iopub.status.idle": "2025-05-20T18:59:41.123203Z",
     "shell.execute_reply": "2025-05-20T18:59:41.122615Z",
     "shell.execute_reply.started": "2025-05-20T18:59:41.109297Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:59:41.809057Z",
     "iopub.status.busy": "2025-05-20T18:59:41.808359Z",
     "iopub.status.idle": "2025-05-20T18:59:41.848886Z",
     "shell.execute_reply": "2025-05-20T18:59:41.848339Z",
     "shell.execute_reply.started": "2025-05-20T18:59:41.809034Z"
    }
   },
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:59:42.229237Z",
     "iopub.status.busy": "2025-05-20T18:59:42.229061Z",
     "iopub.status.idle": "2025-05-20T18:59:42.987609Z",
     "shell.execute_reply": "2025-05-20T18:59:42.986823Z",
     "shell.execute_reply.started": "2025-05-20T18:59:42.229223Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "sns.heatmap(df.corr(), annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:59:47.117224Z",
     "iopub.status.busy": "2025-05-20T18:59:47.116972Z",
     "iopub.status.idle": "2025-05-20T18:59:47.122579Z",
     "shell.execute_reply": "2025-05-20T18:59:47.121872Z",
     "shell.execute_reply.started": "2025-05-20T18:59:47.117206Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(['rms', 'spectral_centroid', 'zero_crossing_rate'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:59:50.301218Z",
     "iopub.status.busy": "2025-05-20T18:59:50.300727Z",
     "iopub.status.idle": "2025-05-20T18:59:50.306069Z",
     "shell.execute_reply": "2025-05-20T18:59:50.305501Z",
     "shell.execute_reply.started": "2025-05-20T18:59:50.301195Z"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:59:55.83857Z",
     "iopub.status.busy": "2025-05-20T18:59:55.837843Z",
     "iopub.status.idle": "2025-05-20T18:59:55.842869Z",
     "shell.execute_reply": "2025-05-20T18:59:55.842273Z",
     "shell.execute_reply.started": "2025-05-20T18:59:55.838549Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns='gender')\n",
    "y = df['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:59:56.600826Z",
     "iopub.status.busy": "2025-05-20T18:59:56.600634Z",
     "iopub.status.idle": "2025-05-20T18:59:56.607809Z",
     "shell.execute_reply": "2025-05-20T18:59:56.607128Z",
     "shell.execute_reply.started": "2025-05-20T18:59:56.600812Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Testing set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:59:59.053352Z",
     "iopub.status.busy": "2025-05-20T18:59:59.052995Z",
     "iopub.status.idle": "2025-05-20T18:59:59.065331Z",
     "shell.execute_reply": "2025-05-20T18:59:59.06462Z",
     "shell.execute_reply.started": "2025-05-20T18:59:59.053335Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogesticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T19:05:43.376564Z",
     "iopub.status.busy": "2025-05-20T19:05:43.376254Z",
     "iopub.status.idle": "2025-05-20T19:05:43.94377Z",
     "shell.execute_reply": "2025-05-20T19:05:43.943182Z",
     "shell.execute_reply.started": "2025-05-20T19:05:43.376543Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression - Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(\"Confusion Matrix:\")\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_lr),annot=True,fmt='d')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T19:07:34.0102Z",
     "iopub.status.busy": "2025-05-20T19:07:34.009623Z",
     "iopub.status.idle": "2025-05-20T19:07:36.644186Z",
     "shell.execute_reply": "2025-05-20T19:07:36.643444Z",
     "shell.execute_reply.started": "2025-05-20T19:07:34.010177Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest - Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', cmap='Greens')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Random Forest Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T19:07:52.322968Z",
     "iopub.status.busy": "2025-05-20T19:07:52.322203Z",
     "iopub.status.idle": "2025-05-20T19:07:52.794261Z",
     "shell.execute_reply": "2025-05-20T19:07:52.793578Z",
     "shell.execute_reply.started": "2025-05-20T19:07:52.322942Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "print(\"XGBoost - Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_xgb), annot=True, fmt='d', cmap='Oranges')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('XGBoost Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T19:07:23.658201Z",
     "iopub.status.busy": "2025-05-20T19:07:23.657897Z",
     "iopub.status.idle": "2025-05-20T19:07:23.821946Z",
     "shell.execute_reply": "2025-05-20T19:07:23.821288Z",
     "shell.execute_reply.started": "2025-05-20T19:07:23.658181Z"
    }
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred_gnb = gnb.predict(X_test)\n",
    "\n",
    "print(\"GaussianNB - Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_gnb))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_gnb), annot=True, fmt='d', cmap='Purples')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('GaussianNB Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6504007,
     "sourceId": 10506096,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
